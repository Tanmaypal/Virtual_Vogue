{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTGBdAKo-Qrq"
      },
      "source": [
        "\n",
        "\n",
        "The notebook created from the official docs can give you Cuda out of memory error even after doing CPU_offload."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gsNG3xytEe5"
      },
      "source": [
        "**TODO** - Add whisper with SDXL with simplified text2img generation of really high quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufD_d64nr08H",
        "outputId": "1022e2bb-fb36-4b4c-a4e2-2b1e3b2f17b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m0.9/1.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rembg\n",
            "  Downloading rembg-2.0.50-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rembg) (1.23.5)\n",
            "Collecting onnxruntime (from rembg)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from rembg) (4.8.0.76)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from rembg) (9.4.0)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from rembg) (1.7.0)\n",
            "Collecting pymatting (from rembg)\n",
            "  Downloading PyMatting-1.1.8-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from rembg) (0.19.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from rembg) (1.11.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from rembg) (4.66.1)\n",
            "Collecting coloredlogs (from onnxruntime->rembg)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (1.12)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->rembg) (3.10.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch->rembg) (2.31.0)\n",
            "Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.10/dist-packages (from pymatting->rembg) (0.56.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (2.31.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (2023.8.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (1.4.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba!=0.49.0->pymatting->rembg) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba!=0.49.0->pymatting->rembg) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (2023.7.22)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->rembg)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime->rembg) (1.3.0)\n",
            "Installing collected packages: humanfriendly, pymatting, coloredlogs, onnxruntime, rembg\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.15.1 pymatting-1.1.8 rembg-2.0.50\n",
            "Collecting pyqrcode\n",
            "  Downloading PyQRCode-1.2.1.zip (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m897.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyqrcode\n",
            "  Building wheel for pyqrcode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyqrcode: filename=PyQRCode-1.2.1-py3-none-any.whl size=36221 sha256=e9d582264da60f1cb2cfdbe531c0dd8b9e9510e010d94885439900bb2c2c915b\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/2d/20/082874e49a32cdcc87ebaf99dd0099fb7774ef30f010dfb6f2\n",
            "Successfully built pyqrcode\n",
            "Installing collected packages: pyqrcode\n",
            "Successfully installed pyqrcode-1.2.1\n",
            "Collecting pypng\n",
            "  Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypng\n",
            "Successfully installed pypng-0.20220715.0\n",
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n",
            "Collecting pyglet\n",
            "  Downloading pyglet-2.0.9-py3-none-any.whl (854 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m854.7/854.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyglet\n",
            "Successfully installed pyglet-2.0.9\n"
          ]
        }
      ],
      "source": [
        "%pip install --quiet --upgrade diffusers transformers accelerate invisible_watermark mediapy\n",
        "!pip install rembg\n",
        "!pip install pyqrcode\n",
        "!pip install pypng\n",
        "!pip install --upgrade openai\n",
        "!pip install pyglet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hRVsA7iYxpMj"
      },
      "outputs": [],
      "source": [
        "use_refiner = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flyer_generation(url):\n",
        "  import mediapy as media\n",
        "  import random\n",
        "  import sys\n",
        "  import torch\n",
        "  import pyqrcode\n",
        "  import png\n",
        "  from pyqrcode import QRCode\n",
        "  from diffusers import DiffusionPipeline\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  pipe = DiffusionPipeline.from_pretrained(\n",
        "      \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "      torch_dtype=torch.float16,\n",
        "      use_safetensors=True,\n",
        "      variant=\"fp16\",\n",
        "      )\n",
        "\n",
        "  if use_refiner:\n",
        "    refiner = DiffusionPipeline.from_pretrained(\n",
        "        \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "        text_encoder_2=pipe.text_encoder_2,\n",
        "        vae=pipe.vae,\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "        variant=\"fp16\",\n",
        "    )\n",
        "\n",
        "    refiner = refiner.to(\"cuda\")\n",
        "\n",
        "    pipe.enable_model_cpu_offload()\n",
        "  else:\n",
        "    pipe = pipe.to(\"cuda\")\n",
        "\n",
        "  prompt = \"Generate an elegant and stylish pink and blue T-shirt and jeans with a realistic girl and a boy standing for fashion editorial [T-shirt:0.9]\"\n",
        "\n",
        "\n",
        "  negative_prompt = \"deformed,bad image, semi-realistic\",\"bad render,bad art, bad anatomy, bad poster, bad text, blurry\"\n",
        "\n",
        "\n",
        "  seed = random.randint(0, sys.maxsize)\n",
        "\n",
        "  images = pipe(\n",
        "      prompt = prompt,\n",
        "      # negative_prompt = negative_prompt,\n",
        "      output_type = \"latent\" if use_refiner else \"pil\",\n",
        "      generator = torch.Generator(\"cuda\").manual_seed(seed),\n",
        "      num_inference_steps=65\n",
        "      ).images\n",
        "\n",
        "  if use_refiner:\n",
        "    images = refiner(\n",
        "        prompt = prompt,\n",
        "        image = images,\n",
        "        ).images\n",
        "\n",
        "  print(f\"Prompt:\\t{prompt}\\nSeed:\\t{seed}\")\n",
        "  media.show_images(images)\n",
        "  # images[0].save(\"output.jpg\")\n",
        "  images[0]\n",
        "  images[0] = images[0].resize((round(images[0].size[0]*1), 800))\n",
        "  images[0].save(\"output.png\")\n",
        "\n",
        "  from rembg import remove\n",
        "\n",
        "  from PIL import Image\n",
        "\n",
        "  input = Image.open('/content/output.png')\n",
        "\n",
        "  output = remove(input)\n",
        "\n",
        "  rgb_im = output.save('/content/girl_background.png')\n",
        "  #convert png to jpeg\n",
        "  input_file = '/content/girl_background.png'\n",
        "  output_file = '/content/a_white_background.jpg'\n",
        "\n",
        "  from PIL import Image\n",
        "\n",
        "  def convert_png_to_jpeg(input_path, output_path):\n",
        "      # Open the PNG image\n",
        "      image = Image.open(input_path)\n",
        "\n",
        "      # If the image has an alpha channel (transparency), convert it to RGB\n",
        "      if image.mode in ('RGBA', 'LA') or (image.mode == 'P' and 'transparency' in image.info):\n",
        "          image = image.convert('RGBA')\n",
        "          background = Image.new('RGBA', image.size, (255, 255, 255))\n",
        "          image = Image.alpha_composite(background, image)\n",
        "          image = image.convert('RGB')\n",
        "\n",
        "      # Save the image as JPEG with white background\n",
        "      image.save(output_path, 'JPEG', quality=90)\n",
        "\n",
        "  convert_png_to_jpeg(input_file, output_file)\n",
        "\n",
        "\n",
        "  url = pyqrcode.create(url)\n",
        "\n",
        "  url.svg('qr.svg',)\n",
        "  url.png('qr.png', scale = 6)\n",
        "\n",
        "  #user_prompt=input(\"Enter the apparel for which flyer to be generated\")\n",
        "  import openai\n",
        "  # openai.api_key = \"your secret API Key\"\n",
        "\n",
        "  openai.api_key = \"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\"\n",
        "  # Define a prompt\n",
        "  prompt = \"Flyer content for \"+\"t-shirt\"+\" in 10 words \"\n",
        "\n",
        "  # Send a request to ChatGPT\n",
        "  response = openai.Completion.create(\n",
        "      engine=\"text-davinci-002\",  # Use the appropriate engine\n",
        "      prompt=prompt,\n",
        "      max_tokens=50  # Adjust based on your needs\n",
        "  )\n",
        "\n",
        "  # Get the model's responsesw\n",
        "  answer1 = response.choices[0].text\n",
        "  print(answer1)\n",
        "\n",
        "  import openai\n",
        "# openai.api_key = \"your secret API Key\"\n",
        "\n",
        "  openai.api_key = \"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\"\n",
        "  # Define a prompt\n",
        "  prompt = \"Sale on \"+\"t-shirt\"+\" in 4 words \"\n",
        "\n",
        "  # Send a request to ChatGPT\n",
        "  response = openai.Completion.create(\n",
        "      engine=\"text-davinci-002\",  # Use the appropriate engine\n",
        "      prompt=prompt,\n",
        "      max_tokens=50  # Adjust based on your needs\n",
        "  )\n",
        "\n",
        "  # Get the model's response\n",
        "  answer2 = response.choices[0].text\n",
        "  print(answer2)\n",
        "\n",
        "  #LOGO\n",
        "  from PIL import Image\n",
        "\n",
        "  logo = Image.open('/content/logo_VV.png')\n",
        "\n",
        "  from PIL import Image\n",
        "  # Open the base image\n",
        "  base_image = Image.open(\"/content/a_white_background.jpg\")\n",
        "\n",
        "  # Open the image to overlay\n",
        "  overlay_image = Image.open(\"/content/logo_VV.png\")\n",
        "\n",
        "  # Paste the overlay image onto the base image at the top-left corner\n",
        "  base_image.paste(overlay_image, (0, 0))\n",
        "  # Save the merged image\n",
        "  base_image.save(\"/content/merged_image.png\")\n",
        "  # Optionally, you can also show the merged image\n",
        "  base_image.show()\n",
        "\n",
        "  from PIL import Image\n",
        "  from PIL import Image\n",
        "  from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "  width, height = 800, 350\n",
        "  white_background = Image.new(\"RGB\", (width, height), \"white\")\n",
        "\n",
        "  draw = ImageDraw.Draw(white_background)\n",
        "  font_size1 = 25\n",
        "  font_size2 = 45\n",
        "  font_path = \"/content/Traffolight.otf\"\n",
        "  text_color = (0, 0, 0)\n",
        "\n",
        "  text1 = answer1\n",
        "  text2 = answer2\n",
        "  font1 = ImageFont.truetype(font_path, font_size1)\n",
        "  font2 = ImageFont.truetype(font_path, font_size2)\n",
        "\n",
        "  text1_width, text1_height = draw.textsize(text1, font=font1)\n",
        "  text1_x = (width - text1_width) // 2\n",
        "  text1_y = (height - text1_height) // 2 - text1_height\n",
        "\n",
        "  text2_width, text2_height = draw.textsize(text2, font=font2)\n",
        "  text2_x = (width - text2_width) // 2\n",
        "  text2_y = (height - text2_height) // 2\n",
        "\n",
        "  draw.text((text1_x, text1_y), text1, fill=text_color, font=font1)\n",
        "  draw.text((text2_x, text2_y), text2, fill=text_color, font=font2)\n",
        "\n",
        "  output_image_path = \"dual_text.jpg\"\n",
        "  white_background.save(output_image_path)\n",
        "  # Define the get_concat_h and get_concat_v functions\n",
        "  def get_concat_h(im1, im2):\n",
        "      dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n",
        "      dst.paste(im1, (0, 0))\n",
        "      dst.paste(im2, (im1.width, 0))\n",
        "      return dst\n",
        "\n",
        "  def get_concat_v(im1, im2):\n",
        "      dst = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
        "      dst.paste(im1, (0, 0))\n",
        "      dst.paste(im2, (0, im1.height))\n",
        "      return dst\n",
        "\n",
        "  # Load your three images (im1, im2, im3)\n",
        "  im1 = Image.open('/content/merged_image.png')\n",
        "  im2 = Image.open('/content/dual_text.jpg')\n",
        "  im3 = Image.open('/content/qr.png')\n",
        "  # Concatenate horizontally (im1 + im2 + im3)\n",
        "  #horizontal_concat = get_concat_h(im1, get_concat_h(im3, im2))\n",
        "\n",
        "  # Concatenate vertically (im1 + im2 + im3)\n",
        "  vertical_concat = get_concat_v(im1, get_concat_h(im3, im2))\n",
        "\n",
        "  # Save the concatenated images\n",
        "  #horizontal_concat.save('horizontal_concatenated.png')\n",
        "  vertical_concat.save('vertical_concatenated.png')"
      ],
      "metadata": {
        "id": "ZBWGFTNkRhwx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flyer_generation('www.shiksha.com/online-courses/articles')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "cqEqCdfDTu_6",
        "outputId": "99bdb33d-69b7-4f60-b78f-e2c06ad42b02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-11e4d62c2853>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflyer_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'www.shiksha.com/online-courses/articles'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-13e6bbbd17ad>\u001b[0m in \u001b[0;36mflyer_generation\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"enter the prompt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   pipe = DiffusionPipeline.from_pretrained(\n\u001b[1;32m     15\u001b[0m       \u001b[0;34m\"stabilityai/stable-diffusion-xl-base-1.0\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'input' referenced before assignment"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jHqx2oc6y27E"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}